\documentclass[hideweeklyreports,noposter]{polytech/polytech}
\usepackage{lmodern}
\usepackage{textcomp}

\usepackage{float}
\usepackage{ltablex}
\usepackage{graphicx}
\usepackage[justification=centering]{caption}

\usepackage{dirtree}

\floatplacement{figure}{H}
\floatplacement{table}{H}

\newcommand{\img}[3]{%
	\begin{center}
		\centering%
		\IfFileExists{./Images/#1}{%
			\includegraphics[scale=#3]{./Images/#1}%
		}{%
			\PackageError{TODO}{Image #1 missing!}{#2}%
			$\boxed{Image\;#1\;missing}$%
		}%
		\captionof{figure}{#2}%
	\end{center}
}
\newcommand{\codec}[1]{\texttt{#1}}

\schooldepartment{di}
\typereport{pasrdi5}
\reportyear{2018-2019}

\title{Crawling web et requête HTTP par serveur proxy}
%\subtitle{}

\student{Thomas}{Couchoud}{thomas.couchoud@etu.univ-tours.fr}
\student{Victor}{Coleau}{victor.coleau@etu.univ-tours.fr}
\academicsupervisor{Mathieu}{Delalandre}{mathieu.delalandre@univ-tours.fr}

\resume{} %TODO
\motcle{} %TODO

\abstract{} %TODO
\keyword{} %TODO

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\RequirePackage[ampersand]{easylist}
\AtBeginEnvironment{easylist}
        {\ListProperties(Progressive*=3ex, Start1=1)}
        {}
        {}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{document}
\part{Introduction}
	Dans notre société moderne l'Internet occupe une place très importante.
	Il offre une quantité pharaonique d'information en libre accès.
	Parmi ces sources d'information, on trouve notamment des << wikis >> qui sont des encyclopédies collaboratives permettant la large diffusion de données.
	
	Malgré leur apparente générosité et leur connaissance des pratiques, ces sites n'apprécient que peu que les données qu'ils fournissent en soient extraites.
	
	Cette nouvelle mane d'information attire les convoitises et polarise les comportements.
	D'un côté nous retrouvons les collecteurs de données cherchant à en agréger et stocker de plus en plus de leur propre chef.
	De l'autre les sites mettant à disposition l'information dont le but paradoxal est de fournir gratuitement tout en conservant l'exclusivité.
	
	Cela entraine une guerre technologique entre crawlers et sites web.
	Les premiers développent des technologies de plus en plus efficaces, rapides et discrètes.
	Les seconds cherchent à contrecarrer les premiers grâce à des techniques de détection de plus en plus sofistiquées.

	Le but de ce projet est d'étudier à la fois les techniques mises en place par les crawler pour se rendre invisible et celles mise en place par les sites pour se défendre.
	Cette recherche se concrétisera par la réalisation d'un crawler effectuant ses connexions au travers d'un proxy.

	\img{crawler.png}{Crawler}{0.5}
	
\part{Veille technique}
	\chapter{Les proxy}
	\chapter{Stratégies de masquage}
		Rotation d'IP
		Rotation des UserAgent
		Gestion de sessions
		Limitation du nombre de requêtes
		Liste noire d'IP
		Réessais
\part{Application: Réalisation d'une crawler avec proxy}
\part{Conclusion}

\appendix		
\end{document}